![avatar](../images/openEuler.png)

版权所有 © 2023  openEuler社区
 您对“本文档”的复制、使用、修改及分发受知识共享(Creative Commons)署名—相同方式共享4.0国际公共许可协议(以下简称“CC BY-SA 4.0”)的约束。为了方便用户理解，您可以通过访问https://creativecommons.org/licenses/by-sa/4.0/ 了解CC BY-SA 4.0的概要 (但不是替代)。CC BY-SA 4.0的完整协议内容您可以访问如下网址获取：https://creativecommons.org/licenses/by-sa/4.0/legalcode。

 修订记录

| 日期 | 修订版本     | 修改描述  | 作者 |
| ---- | ----------- | -------- | ---- |
| 2023/09/04     |     v1.0        |    测试策略初稿      | 周鹏程     |


关键词： 开源大模型 测试策略


摘要：本文是openEuler 23.09版本上开源大模型原生支持的整体测试策略，用于指导该版本后续测试活动的开展


缩略语清单：

| 缩略语 | 英文全名                                         | 中文解释           |
| ------ | ------------------------------------------------ | ------------------ |
| 暂无   | Native support for open source foundation models | 开源大模型原生支持 |

# 特性描述

引入chatglm.cpp与llama.cpp两款开源软件，支持openeuler系统可部署本地可用大模型。

- llama.cpp是基于C/C++实现的LLaMa英文大模型接口，可以支持用户在CPU机器上完成开源大模型的部署和使用。llama.cpp支持多个英文开源大模型的部署，如LLaMa，LLaMa2，Vicuna等。
- chatglm.cpp是基于C/C++实现的ChatGLM大模型接口，可以支持用户在CPU机器上完成开源大模型的部署和使用,chatglm-cpp支持多个中文开源大模型的部署，如ChatGLM-6B，ChatGLM2-6B，Baichuan-13B等。

## 需求清单
|no|feature|status|sig|owner|发布方式|涉及软件包列表|
|:----|:---|:---|:--|:----|:----|:----|
| 1 | 将大模型量化的能力 | Testing | sig-Atune | [@zhoupengcheng](https://gitee.com/zhoupengcheng11)    | everything | chatglm.cpp <br/> llama.cpp |
| 2 | 运行量化后的大模型的能力 | Testing | sig-Atune |    [@zhoupengcheng](https://gitee.com/zhoupengcheng11) | everything | chatglm.cpp <br/> llama.cpp |



## 风险项

| 场景描述 | 设计思路 | 测试重点 | 备注 |
| -------- | -------- | -------- | ---- |
|          |          |          |      |




# 特性分层策略
## 总体测试策略
| 需求        | 开发主体  | 测试主体 | 测试分层策略                                                 |
| ----------- | --------- | -------- | ------------------------------------------------------------ |
| chatglm.cpp | sig-Atune | sig-QA   | 验证chatglm.cpp软件能力，支持将大模型量化以及可使用量化后的大模型 |
| llama.cpp   | sig-Atune | sig-QA   | 验证llama.cpp软件能力，支持将大模型量化以及可使用量化后的大模型 |


## 功能测试

| 功能描述 | 设计思路 | 测试重点 | 备注 |
| ------- | ------- | ------- | ---- |
| chatglm.cpp | 测试chatglm.cpp软件将大模型量化并且使用量化后的大模型 | 验证chatglm.cpp软件能力，支持将大模型量化以及可使用量化后的大模型 |      |
| llama.cpp | 测试llama.cpp软件将大模型量化并且使用量化后的大模型 | 验证llama.cpp软件能力，支持将大模型量化以及可使用量化后的大模型 |      |

## 可靠性测试
| 场景描述 | 设计思路 | 测试预期结果 | 备注 |
| ------- | ------- | ------- | ---- |
| 重复启停服务 | 重复启停大模型对话功能，观察程序是否存在崩溃或者异常 | 正常通过 |      |
| 重复安装卸载 | 重复安装卸载大模型软件，观察程序是否存能正常安装卸载 | 正常通过 |      |

## 稳定性测试
| 专项测试类型 | 专项测试描述 | 测试预期结果 | 备注 |
| ----------- | ----------- | ----------- | ---- |
| 长稳测试 | 长时间启用大模型对话功能，观察程序是否存在崩溃或者异常 | 正常通过 |      |

# 特性测试执行策略

## 特性测试环境描述
| 硬件型号 | 硬件配置信息 | 备注                       |
| -------- | ------------ | -------------------------- |
| 虚拟机   | 8G 8U        | KVM虚拟机:ARM版本和X86版本 |

## 测试计划

|              |            |           |      |              |      |
| ------------ | ---------- | --------- | ---- | ------------ | ---- |
| Stange name  | Begin time | End time  | Days | 测试执行策略 | 备注 |
| Test round 2 | 2023/8/31  | 2023/9/6  | 5    | 全量功能测试 |      |
| Test round 3 | 2023/9/7   | 2023/9/13 | 5    | 回归测试     |      |
| Test round 4 | 2023/9/14  | 2023/9/20 | 5    | 回归测试     |      |


## 入口标准

1. 功能开发已完成
2. 上阶段无block问题遗留
3. 满足各阶段版本转测检查项

## 出口标准

1. 策略规划的测试活动涉及测试用例100%执行完毕
2. 发布特性/新需求/性能基线等满足版本规划目标
3. 无block问题遗留，其它严重问题要有相应规避措施或说明

# 附件

无