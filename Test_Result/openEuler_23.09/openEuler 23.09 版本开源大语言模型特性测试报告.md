![avatar](../images/openEuler.png)

版权所有 © 2023  openEuler社区
 您对“本文档”的复制、使用、修改及分发受知识共享(Creative Commons)署名—相同方式共享4.0国际公共许可协议(以下简称“CC BY-SA 4.0”)的约束。为了方便用户理解，您可以通过访问https://creativecommons.org/licenses/by-sa/4.0/ 了解CC BY-SA 4.0的概要 (但不是替代)。CC BY-SA 4.0的完整协议内容您可以访问如下网址获取：https://creativecommons.org/licenses/by-sa/4.0/legalcode。

修订记录

| 日期      | 修订   版本 | 修改描述 | 作者   |
| --------- | ----------- | -------- | ------ |
| 2023/9/18 | v1.0        | 创建     | 周鹏程 |


 关键词： 开源大语言模型 chatglm.cpp llama.cpp

 

摘要： 本报告主要描述 openEuler 23.09 版本chatglm.cpp 以及 llama.cpp 功能性测试的结果。

 

缩略语清单：

| 缩略语 | 英文全名                                         | 中文解释           |
| ------ | ------------------------------------------------ | ------------------ |
| 暂无   | Native support for open source foundation models | 开源大模型原生支持 |


# 1     特性概述

引入chatglm.cpp与llama.cpp两款开源软件，支持openeuler系统可部署本地可用大模型。

- llama.cpp是基于C/C++实现的LLaMa英文大模型接口，可以支持用户在CPU机器上完成开源大模型的部署和使用。llama.cpp支持多个英文开源大模型的部署，如LLaMa，LLaMa2，Vicuna等。
- chatglm.cpp是基于C/C++实现的ChatGLM大模型接口，可以支持用户在CPU机器上完成开源大模型的部署和使用,chatglm-cpp支持多个中文开源大模型的部署，如ChatGLM-6B，ChatGLM2-6B，Baichuan-13B等。

# 2     特性测试信息

DDE特性测试分别在RC2/RC3/RC4四轮验证，同时验证ARM版本和X86版本

| 版本名称            | 测试起始时间 | 测试结束时间 |
| ------------------- | ------------ | ------------ |
| openEuler 23.09 RC2 | 2023/8/31    | 2023/9/6     |
| openEuler 23.09 RC3 | 2023/9/7     | 2023/9/13    |
| openEuler 23.09 RC4 | 2023/9/14    | 2023/9/20    |

描述特性测试的硬件环境信息

| 硬件型号 | 硬件配置信息 | 备注                       |
| -------- | ------------ | -------------------------- |
| 虚拟机   | 8G 8U        | KVM虚拟机:ARM版本和X86版本 |

# 3     测试结论概述

## 3.1   测试整体结论

开源大模型原生支持特性，共计执行16个用例，对大模型软件将大模型量化的能力 ，运行量化后的大模型的能力进行测试，主要覆盖了功能性测试，可靠性测试，稳定性测试，发现问题已解决，回归通过，无遗留风险，整体质量良好；



共计执行测试用例16个，共计2个软件包,针对对每个软件包设计8个用例如下:

- 功能性测试*5，分别对Q4_0，Q4_1，Q5_0，Q5_1类模型的响应速度进行测试，并进行多种量化精度测试检测软件量化模型的能力。
- 可靠性测试*2，对软件反复安装/卸载进行测试。其中发现问题1个，已闭环验收。
- 长稳性测试*1，对软件提供的对话问答进行服务长稳性测试。



| 序号 | 测试模块名称                    | 子模块质量评估         | 备注 |
| ---- | ------------------------------- | ---------------------- | ---- |
| 1    | chatglm.cpp/llama.cpp 安装/卸载 | 核心功能正常，使用流畅 | 正常 |
| 2    | 长时间启用大模型                | 核心功能正常，使用流畅 | 正常 |
| 3    | 多种量化精度测试  | 核心功能正常，使用流畅 | 正常 |
| 4    | 大模型软件对话能力测试          | 核心功能正常，使用流畅 | 正常 |

### 3.1.1 多种量化精度测试
chatglm.cpp/llama.cpp 分别对以下模型进行了ggml格式转换，均能正常通过。
| 序号 | 量化模型名称               | 子模块质量评估         | 备注 |
| ---- | ------------------------------- | ---------------------- | ---- |
| 1    | pytorch_model-00001-of-00007.bin </br> pytorch_model-00002-of-00007.bin </br> pytorch_model-00003-of-00007.bin </br> pytorch_model-00004-of-00007.bin </br> pytorch_model-00005-of-00007.bin </br> pytorch_model-00006-of-00007.bin </br> | chatglm.cpp核心功能正常，使用流畅 | 正常 |
| 2   | pytorch_model-00001-of-00002.bin </br> pytorch_model-00002-of-00002.bin </br> | llama.cpp核心功能正常，使用流畅 | 正常 |


### 3.1.2 大模型软件对话能力测试
本项目可支持在CPU级别的机器上进行大模型的部署和推理，但是模型推理速度对硬件仍有一定的要求，硬件配置过低可能会导致推理速度过慢，降低使用效率。

表1，表2可作为不同机器配置下推理速度的参考：

表格中Q4_0，Q4_1，Q5_0，Q5_1代表模型的量化精度；ms/token代表模型的推理速度，含义为每个token推理耗费的毫秒数，该值越小推理速度越快；

**表1**  chaglm模型推理速度的测试数据

| ChatGLM-6B            | Q4_0 | Q4_1 | Q5_0 | Q5_1 |
|--------------------------------|------|------|------|------|
| ms/token (CPU @ Platinum 8260) | 74   | 77   | 86   | 89   | 
| 模型大小                      | 3.3G | 3.7G | 4.0G | 4.4G | 
| 内存占用                      | 4.0G | 4.4G | 4.7G | 5.1G |


**表2**  llama模型推理速度的测试数据

| LLaMa-7B            | Q4_0 | Q4_1 | Q5_0 | Q5_1 |
|--------------------------------|------|------|------|------|
| ms/token (CPU @ Platinum 8260) | 55   | 54   | 76   | 83   | 
| 模型大小                      | 3.5G | 3.9G | 4.3G | 6.7G | 
| 内存占用                      | 3.9G | 4.2G | 4.5G | 5.0G |


## 3.2   约束说明

特性使用时涉及到的约束及限制条件

## 3.3   遗留问题分析

### 3.3.1 遗留问题影响以及规避措施

| 问题单号 | 问题描述 | 问题级别 | 问题影响和规避措施 | 当前状态 |
| -------- | -------- | -------- | ------------------ | -------- |
|          |          |          |                    |          |
### 3.3.2 问题统计

| 问题单号 | 问题描述                                             | 问题级别 | 问题影响                                       | 当前状态 |
| -------- | ---------------------------------------------------- | -------- | ---------------------------------------------- | -------- |
| I7XZLW   | chatglm-cpp和sentencepiece含有共同文件，导致安装冲突 | 主要     | chaglm组件安装与其他软件存在文件冲突，阻塞测试 | 已验收   |

|        | 问题总数 | 严重 | 主要 | 次要 | 不重要 |
| ------ | -------- | ---- | ---- | ---- | ------ |
| 数目   | 1        | 0    | 1    | 0    | 0      |
| 百分比 | 100%     | 0%   | 100% | 0%   | 0%     |

# 4     测试执行

## 4.1   测试执行统计数据

| 版本名称 | 测试用例数 | 用例执行结果 | 发现问题单数 |
| -------- | ---------- | ------------ | ------------ |
| openEuler 23.09 RC2 ARM+X86 |      8      |   7 PASS + 1FAIL       | 1            |
| openEuler 23.09 RC3 ARM+X86 | 8 | 8 PASS | 0            |
| openEuler 23.09 RC4 ARM+X86 | 0 | 无 | 0            |


*数据项说明：*

*测试用例数－－到本测试活动结束时，所有可用测试用例数；*

*发现问题单数－－本测试活动总共发现的问题单数。*

## 4.2   后续测试建议

无

# 5     附件

无



 

 
